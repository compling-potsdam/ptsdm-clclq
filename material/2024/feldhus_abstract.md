# Explanation Dialogues for Understanding Language Model Behavior

*Nils Feldhus (DFKI Berlin, & Technical University Berlin)*

*July 16th, 2024*


### Abstract

Framing explanation processes as a dialogue between the human and the model has been motivated in many recent works from the areas of HCI and ML explainability. With the growing popularity of LLMs, the research community has started to present dialogue-based interpretability frameworks for ML problems that is both capable of conveying faithful explanations in human-understandable terms and is generalizable to different datasets, use cases and models. In this talk, I will give an overview of existing conversational XAI systems and evaluation paradigms in performance assessment and user studies.


### Bio

Nils is currently a Research Engineer at the Berlin lab of the German Research Institute for Artificial Intelligence (DFKI) and also a PhD Student at the Technical University Berlin, supervised by Prof. Sebastian MÃ¶ller. His main research interest is in making explainable AI interactive. He is an alumnus of our very own MSc program (Cognitive Systems, University of Potsdam). Before that, he was awarded a BA in Computational Linguistics from Heidelberg University.

