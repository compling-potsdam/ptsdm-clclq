# Toward the automatic acquisition of truth-theoretic models

*Aurelie Herbelot, University of Trento*

*June 29th, 2022*

### Abstract

Large Neural Language Models have been criticised from various perspectives. One aspect of this critique concerns the inability of current systems to account for core semantic competences, in particular reference phenomena. In this talk, I will argue in favour of computational models that take meaning seriously and account for its truth-theoretical aspects. I will first show how a mapping can be automatically learned between corpus data and some underspecified set-theoretic representation of the world. Having identified the limits of this approach, I will then propose a more complete formalisation of set theory in terms of a vector space, amenable to computational treatment. Finally, I will show that such a formalisation can be automatically learned from small data, providing good performance on core semantic tasks.


### Bio

Aurelie is assistant professor at the Center for Mind/Brain Sciences, University of Trento (Italy). Her research is situated at the junction of computational semantics and cognitive science. She leads the Computational Approaches to Language and Meaning (CALM) group, focusing on investigating the link between language and worlds (the real world and others). She is particularly interested in models of semantics that bridge across formal and distributional representations of meaning.
